{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133934b6-de7b-45a2-ab8f-5d631f2a8576",
   "metadata": {},
   "source": [
    "# PySpark DataFrame Exercise Materials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844e7b8-75b1-4e3b-a0bd-370150ccebe2",
   "metadata": {},
   "source": [
    "### Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a93a2c-7804-435b-aa9e-b70cdebb1640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29bf158-844a-4e82-bf20-a8991fb54552",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName(\"PySparkExercise\").getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7afc8-3cc5-4389-a27b-502b81f5156b",
   "metadata": {},
   "source": [
    "### Dataset Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86f252b-a73f-4e15-8fcc-b892f6e97e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37accd75-cd3e-4063-9268-08566377bb75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54759f-d243-4c9f-b78d-cd51a33e79d9",
   "metadata": {},
   "source": [
    "### Define Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19fca8-99e5-44f0-8d5b-7382118f304b",
   "metadata": {},
   "source": [
    "In PySpark, we can define the schema for a DataFrame using the pyspark.sql.types module. To define a schema with specific column names, data types, and nullability constraints.\n",
    "\n",
    "We define the schema using StructType and specify the columns using StructField. The first argument of StructField is the column name, the second argument is the data type (StringType for string columns, IntegerType for integer columns), and the third argument specifies the nullability (True for nullable, False for non-nullable).\n",
    "\n",
    "We can create a DataFrame based on this schema by passing an empty list as the data argument to createDataFrame(). The resulting DataFrame will have the specified column names, data types, and nullability constraints.\n",
    "\n",
    "By printing the schema using df.printSchema(), we can verify that the DataFrame has been created with the defined schema.\n",
    "\n",
    "Please note that the nullability constraint (False in this case) is only enforced when writing data to the DataFrame or performing certain operations. It does not prevent the DataFrame from being created or modified initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b22d6f9-0ee2-4eec-96fe-b0e64b397fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"firstName\",StringType(), True),\n",
    "    StructField(\"midName\",StringType(), True),\n",
    "    StructField(\"lastName\",StringType(), True),\n",
    "    StructField(\"id\",StringType(), True),\n",
    "    StructField(\"gender\",StringType(), True),\n",
    "    StructField(\"salary\",IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c720de-c1c4-4443-b4e3-f0b5826c3949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532343a2-e907-4f1e-a98b-08fb281e8c48",
   "metadata": {},
   "source": [
    "#### Checking Schema and dataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e312c61e-d690-46c8-90ba-162551acb3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- midName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d04d9f-9a40-4869-9679-b0e8e66d61fd",
   "metadata": {},
   "source": [
    "### Checking the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb94da3-3f7f-45af-ad0c-486d8a893c6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "In PySpark, we can use the **df.show()** method to display the top rows of a DataFrame, which is similar to **df.head()** in pandas. Similarly, you can use the df.show(n=3, truncate=False) method to display the last rows of a DataFrame, which is similar to df.tail(n=3) in pandas like showing last 3 of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4454b13d-6c31-4d86-bba3-6636658b50b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------+-----+------+------+\n",
      "|firstName|midName|lastName|id   |gender|salary|\n",
      "+---------+-------+--------+-----+------+------+\n",
      "|James    |       |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose   |        |40288|M     |4000  |\n",
      "|Robert   |       |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne   |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary   |Brown   |     |F     |-1    |\n",
      "+---------+-------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4c732-68b2-44c4-bb5c-6205a0092c39",
   "metadata": {},
   "source": [
    "### DataReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196746fa-c533-4be5-9a13-a413e5377dae",
   "metadata": {},
   "source": [
    "Reading **fire-incidents.csv** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38433ad3-821d-4971-8858-967c4265039e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"./testdata/fire-incidents/fire-incidents.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec2d41-52ef-40a4-a069-d3f55f960cf5",
   "metadata": {},
   "source": [
    "**inferSchema** is set to True to infer the data types automatically. so we don't have to manually like previous in structType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225fe1ee-5d4b-4377-aeee-1699d8b6539b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fire_df = (spark.read.format(\"csv\")\n",
    "           .option(\"header\",True)\n",
    "           .option(\"InferSchema\",True)\n",
    "           .load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c59ea32-e44b-4503-b01b-c145ca13b435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------+\n",
      "|IncidentNumber|       incidentDate|         City|\n",
      "+--------------+-------------------+-------------+\n",
      "|      20104668|2020-09-11 00:00:00|San Francisco|\n",
      "|      20104708|2020-09-11 00:00:00|San Francisco|\n",
      "|      20104648|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104598|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104575|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104477|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104443|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104605|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104474|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104652|2020-09-10 00:00:00|San Francisco|\n",
      "+--------------+-------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select(\"IncidentNumber\",\"incidentDate\",\"City\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1881cda4-e8cc-4925-8344-5a54ca003d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- ExposureNumber: integer (nullable = true)\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- IncidentDate: timestamp (nullable = true)\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- AlarmDtTm: timestamp (nullable = true)\n",
      " |-- ArrivalDtTm: timestamp (nullable = true)\n",
      " |-- CloseDtTm: timestamp (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- ZIPCode: string (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- SuppressionUnits: integer (nullable = true)\n",
      " |-- SuppressionPersonnel: integer (nullable = true)\n",
      " |-- EMSUnits: integer (nullable = true)\n",
      " |-- EMSPersonnel: integer (nullable = true)\n",
      " |-- OtherUnits: integer (nullable = true)\n",
      " |-- OtherPersonnel: integer (nullable = true)\n",
      " |-- FirstUnitOnScene: string (nullable = true)\n",
      " |-- EstimatedPropertyLoss: integer (nullable = true)\n",
      " |-- EstimatedContentsLoss: double (nullable = true)\n",
      " |-- FireFatalities: integer (nullable = true)\n",
      " |-- FireInjuries: integer (nullable = true)\n",
      " |-- CivilianFatalities: integer (nullable = true)\n",
      " |-- CivilianInjuries: integer (nullable = true)\n",
      " |-- NumberofAlarms: integer (nullable = true)\n",
      " |-- PrimarySituation: string (nullable = true)\n",
      " |-- MutualAid: string (nullable = true)\n",
      " |-- ActionTakenPrimary: string (nullable = true)\n",
      " |-- ActionTakenSecondary: string (nullable = true)\n",
      " |-- ActionTakenOther: string (nullable = true)\n",
      " |-- DetectorAlertedOccupants: string (nullable = true)\n",
      " |-- PropertyUse: string (nullable = true)\n",
      " |-- AreaofFireOrigin: string (nullable = true)\n",
      " |-- IgnitionCause: string (nullable = true)\n",
      " |-- IgnitionFactorPrimary: string (nullable = true)\n",
      " |-- IgnitionFactorSecondary: string (nullable = true)\n",
      " |-- HeatSource: string (nullable = true)\n",
      " |-- ItemFirstIgnited: string (nullable = true)\n",
      " |-- HumanFactorsAssociatedwithIgnition: string (nullable = true)\n",
      " |-- StructureType: string (nullable = true)\n",
      " |-- StructureStatus: string (nullable = true)\n",
      " |-- FloorofFireOrigin: integer (nullable = true)\n",
      " |-- FireSpread: string (nullable = true)\n",
      " |-- NoFlameSpead: string (nullable = true)\n",
      " |-- Numberoffloorswithminimumdamage: integer (nullable = true)\n",
      " |-- Numberoffloorswithsignificantdamage: integer (nullable = true)\n",
      " |-- Numberoffloorswithheavydamage: integer (nullable = true)\n",
      " |-- Numberoffloorswithextremedamage: integer (nullable = true)\n",
      " |-- DetectorsPresent: string (nullable = true)\n",
      " |-- DetectorType: string (nullable = true)\n",
      " |-- DetectorOperation: string (nullable = true)\n",
      " |-- DetectorEffectiveness: string (nullable = true)\n",
      " |-- DetectorFailureReason: string (nullable = true)\n",
      " |-- AutomaticExtinguishingSystemPresent: string (nullable = true)\n",
      " |-- AutomaticExtinguishingSytemType: string (nullable = true)\n",
      " |-- AutomaticExtinguishingSytemPerfomance: string (nullable = true)\n",
      " |-- AutomaticExtinguishingSytemFailureReason: string (nullable = true)\n",
      " |-- NumberofSprinklerHeadsOperating: integer (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- AnalysisNeighborhood: string (nullable = true)\n",
      " |-- point: string (nullable = true)\n",
      " |-- NeighborhoodsOld: integer (nullable = true)\n",
      " |-- ZipCodes: integer (nullable = true)\n",
      " |-- FirePreventionDistricts: integer (nullable = true)\n",
      " |-- PoliceDistricts: integer (nullable = true)\n",
      " |-- SupervisorDistricts: integer (nullable = true)\n",
      " |-- CivicCenterHarmReductionProjectBoundary: integer (nullable = true)\n",
      " |-- 2017FixItZones: integer (nullable = true)\n",
      " |-- HSOCZones: integer (nullable = true)\n",
      " |-- CentralMarketTenderloinBoundary: integer (nullable = true)\n",
      " |-- CentralMarketTenderloinBoundaryPolygonUpdated: integer (nullable = true)\n",
      " |-- HSOCZonesasof20180605: integer (nullable = true)\n",
      " |-- Neighborhoods: integer (nullable = true)\n",
      " |-- SFFindNeighborhoods: integer (nullable = true)\n",
      " |-- CurrentPoliceDistricts: integer (nullable = true)\n",
      " |-- CurrentSupervisorDistricts: integer (nullable = true)\n",
      " |-- AnalysisNeighborhoods: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b765b66-4129-41b7-832f-f01505e8595d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = './data/output/fireincidents'\n",
    "fire_df.write.format(\"parquet\").mode(\"overwrite\").save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e0209-59cb-463b-8551-7ba677fa73a3",
   "metadata": {},
   "source": [
    "## Working with Structured Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b4373-ceb2-4e92-b899-74e0d75b5afe",
   "metadata": {},
   "source": [
    "### Reading a JSON File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0993e7cf-1dff-45d8-8882-143120c673e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, FloatType, DateType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba784c42-e70e-4b78-a2a6-4aa929801285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "person_schema = StructType([\n",
    "    StructField(\"id\",IntegerType(), True),\n",
    "    StructField(\"first_name\",StringType(), True),\n",
    "    StructField(\"last_name\",StringType(), True),\n",
    "    StructField(\"fav_movies\",ArrayType(StringType()), True),\n",
    "    StructField(\"salary\",FloatType(), True),\n",
    "    StructField(\"image_url\",StringType(), True),\n",
    "    StructField(\"date_of_birth\",DateType(), True),\n",
    "    StructField(\"active\",BooleanType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a10a7c02-0bd9-4254-a54b-92cd9c5be932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_path = \"./testdata/persondata/persons.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a1056a1-2aa7-45a5-acc1-15b76d3d438a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persons_df = (spark.read.json(json_path, person_schema, multiLine=\"True\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de56f71b-a62f-45b6-8879-87870500abd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- fav_movies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- salary: float (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61cb51d5-5e55-4736-b8cd-bd86b6c2fe41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "|id |first_name|last_name|fav_movies                                                   |salary |image_url                                      |date_of_birth|active|\n",
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "|1  |Drucy     |Poppy    |[I giorni contati]                                           |1463.36|http://dummyimage.com/126x166.png/cc0000/ffffff|1991-02-16   |true  |\n",
      "|2  |Emelyne   |Blaza    |[Musketeer, The, Topralli]                                   |3006.04|http://dummyimage.com/158x106.bmp/cc0000/ffffff|1991-11-02   |false |\n",
      "|3  |Max       |Rettie   |[The Forgotten Space, Make It Happen]                        |1422.88|http://dummyimage.com/237x140.jpg/ff4444/ffffff|1990-03-03   |false |\n",
      "|4  |Ilario    |Kean     |[Up Close and Personal]                                      |3561.36|http://dummyimage.com/207x121.jpg/cc0000/ffffff|1987-06-09   |true  |\n",
      "|5  |Toddy     |Drexel   |[Walk in the Clouds, A]                                      |4934.87|http://dummyimage.com/116x202.png/cc0000/ffffff|1992-10-28   |true  |\n",
      "|6  |Oswald    |Petrolli |[Wing and the Thigh, The (L'aile ou la cuisse)]              |1153.23|http://dummyimage.com/137x172.jpg/5fa2dd/ffffff|1986-09-02   |false |\n",
      "|7  |Adrian    |Clarey   |[Walking Tall, Paradise, Hawaiian Style]                     |1044.73|http://dummyimage.com/244x218.bmp/cc0000/ffffff|1971-08-24   |false |\n",
      "|8  |Dominica  |Goodnow  |[Hearts Divided]                                             |1147.76|http://dummyimage.com/112x203.jpg/dddddd/000000|1973-08-27   |false |\n",
      "|9  |Emory     |Slocomb  |[Snake and Crane Arts of Shaolin (She hao ba bu), Mala Noche]|1082.11|http://dummyimage.com/138x226.jpg/cc0000/ffffff|1974-06-08   |true  |\n",
      "|10 |Jeremias  |Bode     |[Farewell to Arms, A]                                        |3472.63|http://dummyimage.com/243x108.bmp/dddddd/000000|1997-08-02   |true  |\n",
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e0351-0b18-408f-b637-8619da267d73",
   "metadata": {},
   "source": [
    "## Columns and Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f2bfcc0-037e-44bb-9a12-6100cef11cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa74c6e-653e-4045-aa16-8f964e2264ed",
   "metadata": {},
   "source": [
    "### Selecting Multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157631ce-df14-40d8-906e-e6d7ee92b14b",
   "metadata": {},
   "source": [
    "Select expression is similar to expression in SQL way like :\n",
    "\n",
    "SELECT a,b FROM db\n",
    "\n",
    "and also take note a Similiarity pandas and pyspark to selecting columns, Using PySpark:\n",
    "\n",
    "df = df_test.select(\"a\", \"b\")\n",
    "\n",
    "Using pandas:\n",
    "\n",
    "df = df_test.loc[:, [\"a\", \"b\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e065e714-e433-4f51-958c-5ebd36032f57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "|    Oswald| Petrolli|   1986-09-02|\n",
      "|    Adrian|   Clarey|   1971-08-24|\n",
      "|  Dominica|  Goodnow|   1973-08-27|\n",
      "|     Emory|  Slocomb|   1974-06-08|\n",
      "|  Jeremias|     Bode|   1997-08-02|\n",
      "+----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(\"first_name\",\"last_name\",\"date_of_birth\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c620f4-975c-4338-b70b-d11839a03b79",
   "metadata": {},
   "source": [
    "in same way we able to do with this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a0a6b99-9cf9-41e3-acf3-5d41030f8af6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "|    Oswald| Petrolli|   1986-09-02|\n",
      "|    Adrian|   Clarey|   1971-08-24|\n",
      "|  Dominica|  Goodnow|   1973-08-27|\n",
      "|     Emory|  Slocomb|   1974-06-08|\n",
      "|  Jeremias|     Bode|   1997-08-02|\n",
      "+----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(col(\"first_name\"),col(\"last_name\"),col(\"date_of_birth\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1709455a-49fc-4591-9fa3-106451eb18b5",
   "metadata": {},
   "source": [
    "and additionally we also able do with this :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7061f05-8d08-4b9c-8d38-910012c95aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "|    Oswald| Petrolli|   1986-09-02|\n",
      "|    Adrian|   Clarey|   1971-08-24|\n",
      "|  Dominica|  Goodnow|   1973-08-27|\n",
      "|     Emory|  Slocomb|   1974-06-08|\n",
      "|  Jeremias|     Bode|   1997-08-02|\n",
      "+----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(expr(\"first_name\"),expr(\"last_name\"),expr(\"date_of_birth\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea8822-2ca0-4c3a-8321-45555c131ad6",
   "metadata": {},
   "source": [
    "Now what is the difference??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f25bdbb-23bc-4933-9cae-70ab7e44bda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fed70b8e-d8a9-4ae7-bafd-a6c9eb692940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(concat_ws(\" \",col(\"first_name\"),col(\"last_name\")).alias(\"full_name\"),\n",
    "                  col(\"salary\"),\n",
    "                  (col(\"salary\") * 0.10 + col(\"salary\")).alias(\"salary_increase\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcf36404-3223-4d14-8598-86c914959a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(concat_ws(\" \",col(\"first_name\"),col(\"last_name\")).alias(\"full_name\"),\n",
    "                  col(\"salary\"),\n",
    "                  (expr(\"salary * 0.10 + salary\")).alias(\"salary_increase\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa4008-2b60-4046-bc71-5afe635e476b",
   "metadata": {},
   "source": [
    "**The difference is with expr we are able to set whole expression in the bracket quotes, in col must define for each column name suppose we want to add two columns then when using expr is expr(\"col1 + col2\") whereas in col is : (col(\"col_name\") + col(\"col_name\"))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adf33c-365e-4c25-8b54-e7e5da057c94",
   "metadata": {},
   "source": [
    "## Filter and Where Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d4e93-1a3b-4294-962e-767a8d4e463a",
   "metadata": {},
   "source": [
    "### Filter one condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80ad468d-9a44-4675-9d43-1fddac0d9894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|\n",
      "| 14|   Ambrosi| Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 18|     Alfie| Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 19|      Lura|   Follis|[My Life in Pink ...|3331.26|http://dummyimage...|   1998-11-03| false|\n",
      "| 20|      Maxi|    Cluet|[All I Want for C...|4046.46|http://dummyimage...|   1979-05-06| false|\n",
      "| 21|      Dian|    Dancy|[Double, Double, ...| 3720.3|http://dummyimage...|   1998-12-01|  true|\n",
      "| 22|  Theodore| Climance|[Story of the Wee...|3008.56|http://dummyimage...|   1999-01-30| false|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.filter(col(\"salary\") > 3000).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82743069-d718-452a-8ebf-48bdb30cb049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|\n",
      "| 14|   Ambrosi| Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 18|     Alfie| Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 19|      Lura|   Follis|[My Life in Pink ...|3331.26|http://dummyimage...|   1998-11-03| false|\n",
      "| 20|      Maxi|    Cluet|[All I Want for C...|4046.46|http://dummyimage...|   1979-05-06| false|\n",
      "| 21|      Dian|    Dancy|[Double, Double, ...| 3720.3|http://dummyimage...|   1998-12-01|  true|\n",
      "| 22|  Theodore| Climance|[Story of the Wee...|3008.56|http://dummyimage...|   1999-01-30| false|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where(col(\"salary\") > 3000).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50770fe-f5b4-40b0-93b9-e25c1aaaf8e2",
   "metadata": {},
   "source": [
    "### Filter multiple condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35a1db97-0c1c-4a3f-a8bf-566af72c51ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  4|    Ilario|       Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|\n",
      "|  5|     Toddy|     Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|\n",
      "| 10|  Jeremias|       Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|\n",
      "| 14|   Ambrosi|   Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 18|     Alfie|   Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 21|      Dian|      Dancy|[Double, Double, ...| 3720.3|http://dummyimage...|   1998-12-01|  true|\n",
      "| 25|     Kelcy|     Wogdon|    [Iron Mask, The]|4512.51|http://dummyimage...|   2000-10-20|  true|\n",
      "| 27|    Kelila|Harrowsmith|   [Apparition, The]|4651.58|http://dummyimage...|   1973-01-02|  true|\n",
      "| 29|       Eli|  Normabell|[Return to Peyton...|4917.48|http://dummyimage...|   1993-01-02|  true|\n",
      "| 35|     Fanni|      Dyson|     [Wild One, The]|3228.58|http://dummyimage...|   1995-01-09|  true|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where((col(\"salary\") > 3000) & (col(\"active\") == True)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fde9d78a-d9d3-42cc-a46b-f8c61644ed2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  4|    Ilario|       Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|\n",
      "|  5|     Toddy|     Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|\n",
      "| 10|  Jeremias|       Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|\n",
      "| 14|   Ambrosi|   Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 18|     Alfie|   Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 21|      Dian|      Dancy|[Double, Double, ...| 3720.3|http://dummyimage...|   1998-12-01|  true|\n",
      "| 25|     Kelcy|     Wogdon|    [Iron Mask, The]|4512.51|http://dummyimage...|   2000-10-20|  true|\n",
      "| 27|    Kelila|Harrowsmith|   [Apparition, The]|4651.58|http://dummyimage...|   1973-01-02|  true|\n",
      "| 29|       Eli|  Normabell|[Return to Peyton...|4917.48|http://dummyimage...|   1993-01-02|  true|\n",
      "| 35|     Fanni|      Dyson|     [Wild One, The]|3228.58|http://dummyimage...|   1995-01-09|  true|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.filter((col(\"salary\") > 3000) & (col(\"active\") == True)).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2f89d31-43c2-4e72-9c44-8bc5d4784a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a8876b7-c4ba-401e-973d-90df4be8a758",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| 14|   Ambrosi|   Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "| 18|     Alfie|   Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 25|     Kelcy|     Wogdon|    [Iron Mask, The]|4512.51|http://dummyimage...|   2000-10-20|  true|\n",
      "| 32|      Redd|   Akenhead|[Century of the D...| 2470.9|http://dummyimage...|   2000-06-05| false|\n",
      "| 34|     Davis|      Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 61|    Shanna|    Samples|[Thomas in Love (...| 2703.0|http://dummyimage...|   1989-07-07| false|\n",
      "| 69|  Annabell|    Doughty|[Entertaining Ang...|2022.57|http://dummyimage...|   2000-09-03|  true|\n",
      "| 74|     Micky|     Umfrey|[Haunted House, T...|1271.82|http://dummyimage...|   1989-07-04| false|\n",
      "| 88|     Jobie|    Maughan|[Devils on the Do...| 3899.2|http://dummyimage...|   2000-02-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where((year(\"date_of_birth\") == 2000) | (year(\"date_of_birth\") == 1989)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e3552-3163-4f5d-81ce-7506eda7fa04",
   "metadata": {},
   "source": [
    "### Filter Array value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9d1ac1c-1440-40c8-819c-307dbc1ba52f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d89c477-3e03-4989-9d00-0cf3f2efff27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| 11|   Timothy|   Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where(array_contains(col(\"fav_movies\"),\"Land of the Lost\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c40fde-759c-4f61-bba2-1f3e5a396726",
   "metadata": {},
   "source": [
    "## Distinct, Drop Duplicates, Order By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1599efe-edf6-47fa-a014-38e8b81c5d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad75142d-eaac-4b41-adca-808ed548375e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "| false|\n",
      "|  true|\n",
      "|  true|\n",
      "| false|\n",
      "| false|\n",
      "| false|\n",
      "|  true|\n",
      "|  true|\n",
      "+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(col(\"active\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73da6f0-9df1-480a-8b65-25ab401f52db",
   "metadata": {},
   "source": [
    "### Distinct function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89e406f1-a9e6-4f59-8bdf-542eb053e660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(col(\"active\")).distinct().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e62e73-4d05-476e-8011-c1d6eecb0fd8",
   "metadata": {},
   "source": [
    "### Drop Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "928db3d9-40f7-45ea-ac1c-2359ba12c3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|       Sky|1971| false|\n",
      "|   Timothy|1971| false|\n",
      "|    Lucita|1972|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|     Toddy|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(persons_df.select(col(\"first_name\"), \n",
    "           year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "           col(\"active\")).orderBy(\"year\",\"first_name\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1408c2-5296-4d83-a8a7-cfb7e6699f24",
   "metadata": {},
   "source": [
    "** Drop duplicate which means corresponding year only will have matched with distinctive value of active, suppose year has value : 1990, 1991, 1992, 1993, 1994, 1995 and active : true, false, then for each value of year 1990 will have matched with true and false only example : 1990, true and 1990, false. and then continue to respective value in year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc46e2dc-1e4f-48fa-bad8-6e4e6e5286b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropped_df = persons_df.select(col(\"first_name\"), \n",
    "           year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "           col(\"active\")).dropDuplicates([\"year\",\"active\"]).orderBy(\"year\",\"first_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af382a5-ebb7-4f63-8882-05daa340c087",
   "metadata": {},
   "source": [
    "in here first_name of Sky, Toddy, .. etc is removed since their year and active is repeated from previous value sorted by first_name order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55184fca-3330-4e31-b7eb-c807fdb2d7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "|   Balduin|1974| false|\n",
      "|     Emory|1974|  true|\n",
      "|    Janean|1975|  true|\n",
      "|       Bev|1976|  true|\n",
      "| Franciska|1976| false|\n",
      "|     Johny|1977| false|\n",
      "|    Daveta|1978| false|\n",
      "|   Guthrie|1978|  true|\n",
      "|      Maxi|1979| false|\n",
      "|   Melinda|1979|  true|\n",
      "|    Carter|1980| false|\n",
      "|   Loralyn|1980|  true|\n",
      "|     Clive|1981|  true|\n",
      "|   Leanora|1981| false|\n",
      "| Franciska|1982| false|\n",
      "|     Trace|1982|  true|\n",
      "|    Cynthy|1983| false|\n",
      "|        El|1984|  true|\n",
      "|  Thorvald|1984| false|\n",
      "|   Hillyer|1985|  true|\n",
      "|       Rem|1985| false|\n",
      "|     Nahum|1986|  true|\n",
      "|    Oswald|1986| false|\n",
      "|    Ilario|1987|  true|\n",
      "+----------+----+------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped_df.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecf813-eae1-4c09-b1a0-f96acb8e0e99",
   "metadata": {},
   "source": [
    "## Rows and Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3bd00-4232-4a23-8d0c-3a51ca48a750",
   "metadata": {},
   "source": [
    "### Create a New rows to be Unioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b730c12-c3d1-453e-bc5c-43e4ae419d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77a57ce9-be7d-419e-82ad-555e58c52630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "person_row_list = [Row(101, \"Robert\", \"Ownes\", [\"Men in Black III\", \"Home Alone\"], 4300.64, \"http//someimages.com\", \"1964-08-18\", True), \n",
    "                    Row(102, \"Sara\", \"Devine\", [\"Men in Black III\", \"Home Alone\"], 4300.64, \"http//someimages.com\", \"1964-08-18\", True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "443308cd-3131-4826-8dbd-5a8be68d1897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row(101, 'Robert', 'Ownes', ['Men in Black III', 'Home Alone'], 4300.64, 'http//someimages.com', '1964-08-18', True)>,\n",
       " <Row(102, 'Sara', 'Devine', ['Men in Black III', 'Home Alone'], 4300.64, 'http//someimages.com', '1964-08-18', True)>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_row_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8da72-3684-44df-ae0a-dc0db96d6fab",
   "metadata": {},
   "source": [
    "** Noted that The createDataFrame method expects either a list of tuples or a list of lists to create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9550d686-1862-4265-a6f5-9cc937458c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_persons_df = spark.createDataFrame(person_row_list, [\"id\",\"first_name\", \"last_name\", \"fav_movies\", \"salary\", \"image_url\", \"date_of_birth\", \"active\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa0fad43-9538-473c-9a45-624fab6f3d43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|101|    Robert|    Ownes|[Men in Black III...|4300.64|http//someimages.com|   1964-08-18|  true|\n",
      "|102|      Sara|   Devine|[Men in Black III...|4300.64|http//someimages.com|   1964-08-18|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_persons_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e98b1923-637d-4c4e-92af-75e9e3d77adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_persons_df = persons_df.union(new_persons_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0471efec-16ba-4e15-bba0-0b63d2fc071a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies|            salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "|102|      Sara|   Devine|[Men in Black III...|           4300.64|http//someimages.com|   1964-08-18|  true|\n",
      "|101|    Robert|    Ownes|[Men in Black III...|           4300.64|http//someimages.com|   1964-08-18|  true|\n",
      "|100|    Virgie| Domanski|[Horseman, The, S...| 2165.929931640625|http://dummyimage...|   2002-01-05|  true|\n",
      "| 99|   Rozalie|   Wannop|[Suddenly, The No...|1259.6400146484375|http://dummyimage...|   1997-03-25| false|\n",
      "| 98|     Davin|     Labb|[Viva Riva!, Kill...| 1452.739990234375|http://dummyimage...|   1988-01-27|  true|\n",
      "| 97|      Rodi|   Farnan|[Code, The (Menta...|   2325.8798828125|http://dummyimage...|   1972-01-04| false|\n",
      "| 96|       Dew| Coopland|              [Rush]|  2725.56005859375|http://dummyimage...|   1986-11-14| false|\n",
      "| 95|      Cobb|  MacLure|[Storage 24, His ...|1621.1700439453125|http://dummyimage...|   1994-06-28| false|\n",
      "| 94|    Bennie|   Knight|[House on Carroll...| 2370.239990234375|http://dummyimage...|   1977-08-27| false|\n",
      "| 93|    Janean|     Pelz|              [Once]|    4906.919921875|http://dummyimage...|   1975-09-23|  true|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_persons_df.sort(desc(\"id\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f917d65-2b85-4530-abb3-5d2e7aafa0ad",
   "metadata": {},
   "source": [
    "## Adding, Renaming, and Dropping Columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e53abeb7-e5e2-4e85-8c26-e1c5d3bd7d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cdf1ef-617c-46f4-971e-c62b752f7fc6",
   "metadata": {},
   "source": [
    "### Adding new columns Salary Incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bd18746-9e73-43af-8bab-e25881d148ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_persons_df1 = persons_df.withColumn(\"salary_increase\", col(\"salary\") * 0.10 + col(\"salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fadb3ee-9931-4fd1-a272-2f1d2f76398c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|   salary_increase|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|1609.6959838867188|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|  3306.64404296875|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|1565.1680053710938|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|3917.4961181640624|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|  5428.35712890625|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false| 1268.552978515625|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false| 1149.202978515625|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|1262.5360107421875|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|1190.3209838867188|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|  3819.89287109375|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_persons_df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f5d84ca-c42d-444b-900f-0f2f196234bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'first_name',\n",
       " 'last_name',\n",
       " 'fav_movies',\n",
       " 'salary',\n",
       " 'image_url',\n",
       " 'date_of_birth',\n",
       " 'active',\n",
       " 'salary_increase']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_persons_df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a50144-9846-4934-95a3-525083c59fdc",
   "metadata": {},
   "source": [
    "### Renaming Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6433c5c-d6ae-4019-b952-c2d924100cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_persons_df2 = (aug_persons_df1\n",
    "                  .withColumn(\"birth_year\", year(\"date_of_birth\"))\n",
    "                  .withColumnRenamed(\"fav_movies\",\"movies\")\n",
    "                  .withColumn(\"salaryX10\", round(col(\"salary_increase\"),2))\n",
    "                  .drop(\"salary_increase\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29377ca-1f61-4b25-a163-2ce13c7f9676",
   "metadata": {},
   "source": [
    "** Adding \"birth_year\" column, renaming fav movies to movies, add new column \"salaryX10\" which round 2 decimals of \"salary_increas\", and drop the current \"saalry_increase\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9810cc3c-63a9-417f-ac72-4bd93dc7f99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+---------+\n",
      "| id|first_name|last_name|              movies| salary|           image_url|date_of_birth|active|birth_year|salaryX10|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+---------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|      1991|   1609.7|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|      1991|  3306.64|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|      1990|  1565.17|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|      1987|   3917.5|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|      1992|  5428.36|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|      1986|  1268.55|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|      1971|   1149.2|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|      1973|  1262.54|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|      1974|  1190.32|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|      1997|  3819.89|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_persons_df2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174d2dd-8274-437d-96f6-2fbe624cacf5",
   "metadata": {},
   "source": [
    "## Working with Missing or Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4c80ef6-58ea-47e5-8fa3-2d7deaae54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_list = [Row(None, None, None),\n",
    "                Row(None, None, 2020),\n",
    "                Row(\"John Doe\", \"Awesome movie\", None),\n",
    "                Row(None, \"Awesome movie\", 2021),\n",
    "                Row(\"Mary jane\", None, 2019),\n",
    "                Row(\"Vikter Duplaix\", \"Not another teen movie\", 2001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bbed073e-fc1d-4ac0-8fdb-908c27da6b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_movies_columns = [\"Actor\", \"Title\", \"Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4196387f-91e9-4bfb-9017-84b271331e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_movies_df = spark.createDataFrame(data= bad_movies_list, schema= bad_movies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c640e285-9ab5-4e67-97b8-08d9ffa87e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|         Actor|               Title|Year|\n",
      "+--------------+--------------------+----+\n",
      "|          null|                null|null|\n",
      "|          null|                null|2020|\n",
      "|      John Doe|       Awesome movie|null|\n",
      "|          null|       Awesome movie|2021|\n",
      "|     Mary jane|                null|2019|\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02370135-335e-47df-ad0d-0f3cd2ae156f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Actor: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2408b3b-6f32-4cf1-b7a8-752b16d27396",
   "metadata": {},
   "source": [
    "### Dropping NA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de6abe-ce39-4032-9977-e75471d68e4d",
   "metadata": {},
   "source": [
    "In Apache Spark's DataFrame drop() function, the drop method can accept one or more parameters. Here's an overview of the parameters commonly used with the drop() function:\n",
    "\n",
    "col(s) (string or list of strings): Specifies the name(s) of the column(s) to drop from the DataFrame. It can be a single column name as a string or a list of column names.\n",
    "\n",
    "subset (string or list of strings): Specifies the name(s) of the column(s) to drop from the DataFrame. It can be a single column name as a string or a list of column names. This parameter is an alias for the col(s) parameter and can be used interchangeably.\n",
    "\n",
    "how (string): Specifies the drop behavior. It accepts the following values:\n",
    "\n",
    "\"any\": Drops a row if it contains at least one null or NaN value in any of the specified columns (default behavior).\n",
    "\n",
    "\"all\": Drops a row only if all the specified columns have null or NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a566a-911b-4470-90a5-daf076ca0d1a",
   "metadata": {},
   "source": [
    "#### Dropping any NULL Rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "582bc30d-1a76-463d-b0fe-bc79577904a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|         Actor|               Title|Year|\n",
      "+--------------+--------------------+----+\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89b660a8-348b-4fe2-beb3-8b1a7f187f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|         Actor|               Title|Year|\n",
      "+--------------+--------------------+----+\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.na.drop(\"any\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbd626-c193-46cc-a7fc-eb21ef93b2d7",
   "metadata": {},
   "source": [
    "#### Dropping Rows which all columns is NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "768c044e-299b-4aa1-aa4c-28f37d1c83c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|         Actor|               Title|Year|\n",
      "+--------------+--------------------+----+\n",
      "|          null|                null|2020|\n",
      "|      John Doe|       Awesome movie|null|\n",
      "|          null|       Awesome movie|2021|\n",
      "|     Mary jane|                null|2019|\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c1897d-1980-47d4-a900-8064f33413c2",
   "metadata": {},
   "source": [
    "#### Using filter to Show NOT NULL Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624d338-f931-447c-9348-cac75d914f56",
   "metadata": {},
   "source": [
    "can use the filter() function to filter rows in a DataFrame based on certain conditions, such as checking if a column is not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96ffee81-7db4-439b-9752-ae46e6a70d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|         Actor|               Title|Year|\n",
      "+--------------+--------------------+----+\n",
      "|      John Doe|       Awesome movie|null|\n",
      "|     Mary jane|                null|2019|\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.filter(col(\"Actor\").isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f68b190d-ba56-4c83-92a4-405c54e57ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|         Actor|               Title|Year|\n",
      "+--------------+--------------------+----+\n",
      "|      John Doe|       Awesome movie|null|\n",
      "|     Mary jane|                null|2019|\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.filter(col(\"Actor\").isNull() == False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d506a-5dfd-42f6-b1ae-9fe12be5da50",
   "metadata": {},
   "source": [
    "## Working User Defined Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b760b6d2-e5d2-4464-99ed-56c6d5154abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "126a1442-daa3-4a79-a5cb-85c220238b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "students_list = [Row(\"John\", 80),\n",
    "                Row(\"Mary\", 70),\n",
    "                Row(\"Jane\",50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6bcc9316-3a82-4ae0-ae34-162f0614bb22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "students_columns = [\"Name\", \"Mark\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a857b8d-6e89-4178-a15d-77b4a6a0c21c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "students_df = spark.createDataFrame(data=students_list, schema=students_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cfc3766c-f020-462d-8c1a-fb2838b8b8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|Name|Mark|\n",
      "+----+----+\n",
      "|John|  80|\n",
      "|Mary|  70|\n",
      "|Jane|  50|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9357a-2477-4020-9e45-606a1b01e29a",
   "metadata": {},
   "source": [
    "### Define a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f86ad433-212f-43bf-88b5-60ccf747cd16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradeStudents(score:int):\n",
    "    grade = ''\n",
    "    if(score >= 80):\n",
    "        grade='Excelent'\n",
    "    elif(score>=70):\n",
    "        grade='Average'\n",
    "    else:\n",
    "        grade='Poor'\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53059dfe-68e9-4626-a11a-d7e95ebd2874",
   "metadata": {},
   "source": [
    "Created a UDF using udf() and specified the function gradeStudents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a6bcf33-3266-4814-ae2a-723ca3c33ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "letterGradeUDF = udf(gradeStudents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57b54ca6-cc60-4dc2-af3c-8db9909a136e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+\n",
      "|Name|Mark|   Grade|\n",
      "+----+----+--------+\n",
      "|John|  80|Excelent|\n",
      "|Mary|  70| Average|\n",
      "|Jane|  50|    Poor|\n",
      "+----+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select(col(\"Name\"),col(\"Mark\"), letterGradeUDF(col(\"Mark\")).alias(\"Grade\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277f655-0314-4f4a-858a-251ccc9d0a21",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "671ce0fc-19e5-4fd2-b906-cf918211fd40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flights_file = \"./testdata/flights/flight-summary.csv\"\n",
    "flights_summary_df = (spark.read.format(\"csv\")\n",
    "                      .option(\"header\",\"true\")\n",
    "                      .option(\"inferSchema\",\"true\")\n",
    "                      .load(flights_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a83f79d-d005-4481-a800-e46c77ac8c07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "|origin_code|      origin_airport|    origin_city|origin_state|dest_code|        dest_airport|       dest_city|dest_state|count|\n",
      "+-----------+--------------------+---------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "|        BQN|Rafael Hernndez ...|      Aguadilla|          PR|      MCO|Orlando Internati...|         Orlando|        FL|  441|\n",
      "|        PHL|Philadelphia Inte...|   Philadelphia|          PA|      MCO|Orlando Internati...|         Orlando|        FL| 4869|\n",
      "|        MCI|Kansas City Inter...|    Kansas City|          MO|      IAH|George Bush Inter...|         Houston|        TX| 1698|\n",
      "|        SPI|Abraham Lincoln C...|    Springfield|          IL|      ORD|Chicago O'Hare In...|         Chicago|        IL|  998|\n",
      "|        SNA|John Wayne Airpor...|      Santa Ana|          CA|      PHX|Phoenix Sky Harbo...|         Phoenix|        AZ| 3846|\n",
      "|        LBB|Lubbock Preston S...|        Lubbock|          TX|      DEN|Denver Internatio...|          Denver|        CO|  618|\n",
      "|        ORD|Chicago O'Hare In...|        Chicago|          IL|      PDX|Portland Internat...|        Portland|        OR| 2149|\n",
      "|        EWR|Newark Liberty In...|         Newark|          NJ|      STT|Cyril E. King Air...|Charlotte Amalie|        VI|  239|\n",
      "|        ATL|Hartsfield-Jackso...|        Atlanta|          GA|      GSP|Greenville-Sparta...|           Greer|        SC| 2470|\n",
      "|        MCI|Kansas City Inter...|    Kansas City|          MO|      MKE|General Mitchell ...|       Milwaukee|        WI|  612|\n",
      "|        PBI|Palm Beach Intern...|West Palm Beach|          FL|      DCA|Ronald Reagan Was...|       Arlington|        VA|  978|\n",
      "|        SMF|Sacramento Intern...|     Sacramento|          CA|      BUR|Bob Hope Airport...|         Burbank|        CA| 2092|\n",
      "|        MDW|Chicago Midway In...|        Chicago|          IL|      MEM|Memphis Internati...|         Memphis|        TN|  628|\n",
      "|        LAS|McCarran Internat...|      Las Vegas|          NV|      LIT|Bill and Hillary ...|     Little Rock|        AR|  334|\n",
      "|        TPA|Tampa Internation...|          Tampa|          FL|      ACY|Atlantic City Int...|   Atlantic City|        NJ|  335|\n",
      "|        DSM|Des Moines Intern...|     Des Moines|          IA|      EWR|Newark Liberty In...|          Newark|        NJ|  191|\n",
      "|        FSD|Sioux Falls Regio...|    Sioux Falls|          SD|      ATL|Hartsfield-Jackso...|         Atlanta|        GA|  329|\n",
      "|        SJC|Norman Y. Mineta ...|       San Jose|          CA|      LIH|       Lihue Airport|           Lihue|        HI|  190|\n",
      "|        CLE|Cleveland Hopkins...|      Cleveland|          OH|      SJU|Luis Muoz Marn ...|        San Juan|        PR|   43|\n",
      "|        CPR|Natrona County In...|         Casper|          WY|      DEN|Denver Internatio...|          Denver|        CO|  956|\n",
      "+-----------+--------------------+---------------+------------+---------+--------------------+----------------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_summary_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf91e610-e9e2-4b65-a732-fa0016e75048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin_code: string (nullable = true)\n",
      " |-- origin_airport: string (nullable = true)\n",
      " |-- origin_city: string (nullable = true)\n",
      " |-- origin_state: string (nullable = true)\n",
      " |-- dest_code: string (nullable = true)\n",
      " |-- dest_airport: string (nullable = true)\n",
      " |-- dest_city: string (nullable = true)\n",
      " |-- dest_state: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_summary_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2936ae7f-be9a-456e-8455-45a90d93502d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flights_summary_df = flights_summary_df.withColumnRenamed(\"count\",\"flights_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4cec32e1-16a0-4fa6-b35b-e033ad8b4017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+---------------+------------+---------+--------------------+----------------+----------+-------------+\n",
      "|origin_code|      origin_airport|    origin_city|origin_state|dest_code|        dest_airport|       dest_city|dest_state|flights_count|\n",
      "+-----------+--------------------+---------------+------------+---------+--------------------+----------------+----------+-------------+\n",
      "|        BQN|Rafael Hernndez ...|      Aguadilla|          PR|      MCO|Orlando Internati...|         Orlando|        FL|          441|\n",
      "|        PHL|Philadelphia Inte...|   Philadelphia|          PA|      MCO|Orlando Internati...|         Orlando|        FL|         4869|\n",
      "|        MCI|Kansas City Inter...|    Kansas City|          MO|      IAH|George Bush Inter...|         Houston|        TX|         1698|\n",
      "|        SPI|Abraham Lincoln C...|    Springfield|          IL|      ORD|Chicago O'Hare In...|         Chicago|        IL|          998|\n",
      "|        SNA|John Wayne Airpor...|      Santa Ana|          CA|      PHX|Phoenix Sky Harbo...|         Phoenix|        AZ|         3846|\n",
      "|        LBB|Lubbock Preston S...|        Lubbock|          TX|      DEN|Denver Internatio...|          Denver|        CO|          618|\n",
      "|        ORD|Chicago O'Hare In...|        Chicago|          IL|      PDX|Portland Internat...|        Portland|        OR|         2149|\n",
      "|        EWR|Newark Liberty In...|         Newark|          NJ|      STT|Cyril E. King Air...|Charlotte Amalie|        VI|          239|\n",
      "|        ATL|Hartsfield-Jackso...|        Atlanta|          GA|      GSP|Greenville-Sparta...|           Greer|        SC|         2470|\n",
      "|        MCI|Kansas City Inter...|    Kansas City|          MO|      MKE|General Mitchell ...|       Milwaukee|        WI|          612|\n",
      "|        PBI|Palm Beach Intern...|West Palm Beach|          FL|      DCA|Ronald Reagan Was...|       Arlington|        VA|          978|\n",
      "|        SMF|Sacramento Intern...|     Sacramento|          CA|      BUR|Bob Hope Airport...|         Burbank|        CA|         2092|\n",
      "|        MDW|Chicago Midway In...|        Chicago|          IL|      MEM|Memphis Internati...|         Memphis|        TN|          628|\n",
      "|        LAS|McCarran Internat...|      Las Vegas|          NV|      LIT|Bill and Hillary ...|     Little Rock|        AR|          334|\n",
      "|        TPA|Tampa Internation...|          Tampa|          FL|      ACY|Atlantic City Int...|   Atlantic City|        NJ|          335|\n",
      "|        DSM|Des Moines Intern...|     Des Moines|          IA|      EWR|Newark Liberty In...|          Newark|        NJ|          191|\n",
      "|        FSD|Sioux Falls Regio...|    Sioux Falls|          SD|      ATL|Hartsfield-Jackso...|         Atlanta|        GA|          329|\n",
      "|        SJC|Norman Y. Mineta ...|       San Jose|          CA|      LIH|       Lihue Airport|           Lihue|        HI|          190|\n",
      "|        CLE|Cleveland Hopkins...|      Cleveland|          OH|      SJU|Luis Muoz Marn ...|        San Juan|        PR|           43|\n",
      "|        CPR|Natrona County In...|         Casper|          WY|      DEN|Denver Internatio...|          Denver|        CO|          956|\n",
      "+-----------+--------------------+---------------+------------+---------+--------------------+----------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_summary_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e52fa9-69c2-4362-b5fa-bb1bc6549617",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b981d0c7-869f-43e9-b46e-e82f7841002c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+\n",
      "|count(origin_airport)|count(dest_airport)|\n",
      "+---------------------+-------------------+\n",
      "|                 4693|               4693|\n",
      "+---------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_summary_df.select(count(col(\"origin_airport\")), count(\"dest_airport\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3cd636e-5854-4684-9490-d08db86b1771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----+\n",
      "|         Actor|               Title|Year|\n",
      "+--------------+--------------------+----+\n",
      "|          null|                null|null|\n",
      "|          null|                null|2020|\n",
      "|      John Doe|       Awesome movie|null|\n",
      "|          null|       Awesome movie|2021|\n",
      "|     Mary jane|                null|2019|\n",
      "|Vikter Duplaix|Not another teen ...|2001|\n",
      "+--------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2e419ca0-592e-4f01-bc5a-bdfc739599cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------+--------+\n",
      "|count(Actor)|count(Title)|count(Year)|count(1)|\n",
      "+------------+------------+-----------+--------+\n",
      "|           3|           3|          4|       6|\n",
      "+------------+------------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.select(count(col(\"Actor\")), count(col(\"Title\")), count(col(\"Year\")), count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515aa19c-3dd4-4bcb-8c34-6480d601de21",
   "metadata": {},
   "source": [
    "Counting is process count Non Null elements in the corresponding columns, but using count(\"*\") will count all value including NULL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0165f8-a248-4479-9735-cc00e46bae8c",
   "metadata": {},
   "source": [
    "### Count Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "45a04fb4-9768-4065-a7f9-b1cf43474759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "53acda1c-e1d0-4f5b-a9a1-ce2fd679e27f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------------------------+-------------+\n",
      "|count(DISTINCT origin_airport)|count(DISTINCT dest_airport)|Total Columns|\n",
      "+------------------------------+----------------------------+-------------+\n",
      "|                           322|                         322|         4693|\n",
      "+------------------------------+----------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_summary_df.select(countDistinct(col(\"origin_airport\")), countDistinct(\"dest_airport\"), count(\"*\").alias(\"Total Columns\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56139833-e46d-478e-99f2-3627e1579b13",
   "metadata": {},
   "source": [
    "### SUM, AVG, MAX, MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f59d0a7b-b63d-459f-af45-3fb0e542c43b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, avg, sum, sumDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c29c70e9-c3d9-4722-b345-aea56199983c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|min(flights_count)|max(flights_count)|\n",
      "+------------------+------------------+\n",
      "|                 1|             13744|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_summary_df.select(min(col(\"flights_count\")), max(col(\"flights_count\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1eedfeb4-1331-4575-aa39-ede3961f3318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------------------------+\n",
      "|avg(flights_count)|(sum(flights_count) / count(flights_count))|\n",
      "+------------------+-------------------------------------------+\n",
      "|1136.3549968037503|                         1136.3549968037503|\n",
      "+------------------+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_summary_df.select(avg(col(\"flights_count\")), sum(col(\"flights_count\"))/count(col(\"flights_count\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55a83d-8b34-4edd-b077-f9e3488409b8",
   "metadata": {},
   "source": [
    "### SUM DISTINCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4e453ae0-b60a-4a55-b205-3a1ac5b56dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|Name|Mark|\n",
      "+----+----+\n",
      "|John|  80|\n",
      "|Mary|  70|\n",
      "|Jane|  50|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9629b3fa-3734-48d5-bf15-cfe077a19988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|sum(Mark)|\n",
      "+---------+\n",
      "|      200|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select(sum(col(\"Mark\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "838ab0d2-4930-4303-8404-53c926917fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_students_df = students_df.union(students_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e4cf1d1-24d0-46df-bf7d-a8d80d8cff84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|Name|Mark|\n",
      "+----+----+\n",
      "|John|  80|\n",
      "|Mary|  70|\n",
      "|Jane|  50|\n",
      "|John|  80|\n",
      "|Mary|  70|\n",
      "|Jane|  50|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4cbebe47-656f-457d-be45-6a287a51408c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|sum(Mark)|sum(DISTINCT Mark)|\n",
      "+---------+------------------+\n",
      "|      400|               200|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_students_df.select(sum(col(\"Mark\")), sumDistinct(col(\"Mark\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46bae7-16ac-41aa-8971-a5e54b3f61d8",
   "metadata": {},
   "source": [
    "### Aggregating Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d761f72-61fc-4000-94c9-e26d7028d459",
   "metadata": {},
   "source": [
    "Checking the maximum flight counts from origin_airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "310d9659-d8af-44d3-8a32-6ee7b9660e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|      origin_airport|max_flights_count|\n",
      "+--------------------+-----------------+\n",
      "|San Francisco Int...|            13744|\n",
      "|Los Angeles Inter...|            13457|\n",
      "|John F. Kennedy I...|            12016|\n",
      "|McCarran Internat...|             9715|\n",
      "|LaGuardia Airport...|             9639|\n",
      "+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flights_summary_df.groupBy(\"origin_airport\").agg(max(\"flights_count\").alias(\"max_flights_count\")).orderBy(\"max_flights_count\",ascending=False)).show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b6093-54de-44c9-961d-f896ec6bf090",
   "metadata": {},
   "source": [
    "checking sample maximum value using filter of \"San Francisco Intl. Airport\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "50ca6f2b-9838-4383-8685-eeb56b86bcc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+------------+---------+--------------------+-----------------+----------+-------------+\n",
      "|origin_code|      origin_airport|  origin_city|origin_state|dest_code|        dest_airport|        dest_city|dest_state|flights_count|\n",
      "+-----------+--------------------+-------------+------------+---------+--------------------+-----------------+----------+-------------+\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      LAX|Los Angeles Inter...|      Los Angeles|        CA|        13744|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      JFK|John F. Kennedy I...|         New York|        NY|         8440|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      LAS|McCarran Internat...|        Las Vegas|        NV|         7995|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      ORD|Chicago O'Hare In...|          Chicago|        IL|         7380|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      SEA|Seattle-Tacoma In...|          Seattle|        WA|         6932|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      SAN|San Diego Interna...|        San Diego|        CA|         6917|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      DEN|Denver Internatio...|           Denver|        CO|         5066|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      EWR|Newark Liberty In...|           Newark|        NJ|         5025|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      PHX|Phoenix Sky Harbo...|          Phoenix|        AZ|         4856|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      DFW|Dallas/Fort Worth...|Dallas-Fort Worth|        TX|         4555|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      SNA|John Wayne Airpor...|        Santa Ana|        CA|         4314|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      PDX|Portland Internat...|         Portland|        OR|         4197|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      BOS|Gen. Edward Lawre...|           Boston|        MA|         3907|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      IAD|Washington Dulles...|        Chantilly|        VA|         3478|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      IAH|George Bush Inter...|          Houston|        TX|         3426|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      SLC|Salt Lake City In...|   Salt Lake City|        UT|         3249|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      ATL|Hartsfield-Jackso...|          Atlanta|        GA|         3127|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      MSP|Minneapolis-Saint...|      Minneapolis|        MN|         2449|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      ONT|Ontario Internati...|          Ontario|        CA|         2174|\n",
      "|        SFO|San Francisco Int...|San Francisco|          CA|      PSP|Palm Springs Inte...|     Palm Springs|        CA|         2140|\n",
      "+-----------+--------------------+-------------+------------+---------+--------------------+-----------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_summary_df.filter(col(\"origin_airport\") == \"San Francisco International Airport\").orderBy(\"flights_count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba9693-3a8c-46db-a639-5d7606d3e525",
   "metadata": {},
   "source": [
    "Sum of flights_count where origin airport is \"San Francisco Intl. airport\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "946adf26-62fb-45ab-96c8-5d374bd53e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|      origin_airport|sum_flights_count|\n",
      "+--------------------+-----------------+\n",
      "|Hartsfield-Jackso...|           346836|\n",
      "|Chicago O'Hare In...|           285884|\n",
      "|Dallas/Fort Worth...|           239551|\n",
      "|Denver Internatio...|           196055|\n",
      "|Los Angeles Inter...|           194673|\n",
      "|San Francisco Int...|           148008|\n",
      "|Phoenix Sky Harbo...|           146815|\n",
      "|George Bush Inter...|           146622|\n",
      "|McCarran Internat...|           133181|\n",
      "|Minneapolis-Saint...|           112117|\n",
      "|Orlando Internati...|           110982|\n",
      "|Seattle-Tacoma In...|           110899|\n",
      "|Detroit Metropoli...|           108500|\n",
      "|Gen. Edward Lawre...|           107847|\n",
      "|Newark Liberty In...|           101772|\n",
      "|Charlotte Douglas...|           100324|\n",
      "|LaGuardia Airport...|            99605|\n",
      "|Salt Lake City In...|            97210|\n",
      "|John F. Kennedy I...|            93811|\n",
      "|Baltimore-Washing...|            86079|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf_flights_df = (flights_summary_df.groupBy(\"origin_airport\").agg(sum(\"flights_count\").alias(\"sum_flights_count\")).orderBy(\"sum_flights_count\",ascending=False))\n",
    "sf_flights_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff0fc8f2-2953-4055-9cd8-861cc5b5ff8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|      origin_airport|sum_flights_count|\n",
      "+--------------------+-----------------+\n",
      "|San Francisco Int...|           148008|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf_flights_df.filter(col(\"origin_airport\") == \"San Francisco International Airport\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41879c0c-66d2-4000-8224-e2bb6fc5e343",
   "metadata": {},
   "source": [
    "Fast way to query with groupBy - where clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3f2c5ea6-5d3f-4b19-9679-21c8cdf399b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|      origin_airport|sum_flights_count|\n",
      "+--------------------+-----------------+\n",
      "|San Francisco Int...|           148008|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flights_summary_df.groupBy(\"origin_airport\").agg(sum(\"flights_count\").alias(\"sum_flights_count\")).where(col(\"origin_airport\") == \"San Francisco International Airport\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e58e8-4fe1-4427-b912-bdcb40298943",
   "metadata": {},
   "source": [
    "### Group By multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa07944-52aa-498a-ada8-fc5e6f937b88",
   "metadata": {},
   "source": [
    "Check for every \"San Francisco Intl Airport\" total flights to destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "221c1d5c-0dd2-49ba-bd56-55a1d2799713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+\n",
      "|      origin_airport|        dest_airport|sum_flights_count|\n",
      "+--------------------+--------------------+-----------------+\n",
      "|San Francisco Int...|Los Angeles Inter...|            13744|\n",
      "|San Francisco Int...|John F. Kennedy I...|             8440|\n",
      "|San Francisco Int...|McCarran Internat...|             7995|\n",
      "|San Francisco Int...|Chicago O'Hare In...|             7380|\n",
      "|San Francisco Int...|Seattle-Tacoma In...|             6932|\n",
      "|San Francisco Int...|San Diego Interna...|             6917|\n",
      "|San Francisco Int...|Denver Internatio...|             5066|\n",
      "|San Francisco Int...|Newark Liberty In...|             5025|\n",
      "|San Francisco Int...|Phoenix Sky Harbo...|             4856|\n",
      "|San Francisco Int...|Dallas/Fort Worth...|             4555|\n",
      "|San Francisco Int...|John Wayne Airpor...|             4314|\n",
      "|San Francisco Int...|Portland Internat...|             4197|\n",
      "|San Francisco Int...|Gen. Edward Lawre...|             3907|\n",
      "|San Francisco Int...|Washington Dulles...|             3478|\n",
      "|San Francisco Int...|George Bush Inter...|             3426|\n",
      "|San Francisco Int...|Salt Lake City In...|             3249|\n",
      "|San Francisco Int...|Hartsfield-Jackso...|             3127|\n",
      "|San Francisco Int...|Minneapolis-Saint...|             2449|\n",
      "|San Francisco Int...|Ontario Internati...|             2174|\n",
      "|San Francisco Int...|Palm Springs Inte...|             2140|\n",
      "+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flights_summary_df.groupBy(\"origin_airport\",\"dest_airport\")\n",
    " .agg(sum(\"flights_count\").alias(\"sum_flights_count\"))\n",
    " .where(col(\"origin_airport\") == \"San Francisco International Airport\")\n",
    " .orderBy(\"sum_flights_count\", ascending=False)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4653d289-8d9e-4929-8189-962bb3b669eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+\n",
      "|      origin_airport|        dest_airport|sum_flights_count|\n",
      "+--------------------+--------------------+-----------------+\n",
      "|San Francisco Int...|Los Angeles Inter...|            13744|\n",
      "|Los Angeles Inter...|San Francisco Int...|            13457|\n",
      "|John F. Kennedy I...|Los Angeles Inter...|            12016|\n",
      "|Los Angeles Inter...|John F. Kennedy I...|            12015|\n",
      "|McCarran Internat...|Los Angeles Inter...|             9715|\n",
      "|LaGuardia Airport...|Chicago O'Hare In...|             9639|\n",
      "|Los Angeles Inter...|McCarran Internat...|             9594|\n",
      "|Chicago O'Hare In...|LaGuardia Airport...|             9575|\n",
      "|San Francisco Int...|John F. Kennedy I...|             8440|\n",
      "|John F. Kennedy I...|San Francisco Int...|             8437|\n",
      "|     Kahului Airport|Honolulu Internat...|             8313|\n",
      "|Honolulu Internat...|     Kahului Airport|             8282|\n",
      "|Los Angeles Inter...|Chicago O'Hare In...|             8256|\n",
      "|Hartsfield-Jackso...|LaGuardia Airport...|             8234|\n",
      "|LaGuardia Airport...|Hartsfield-Jackso...|             8215|\n",
      "|Hartsfield-Jackso...|Orlando Internati...|             8202|\n",
      "|Orlando Internati...|Hartsfield-Jackso...|             8202|\n",
      "|San Francisco Int...|McCarran Internat...|             7995|\n",
      "|Chicago O'Hare In...|Los Angeles Inter...|             7941|\n",
      "|Dallas/Fort Worth...|Chicago O'Hare In...|             7870|\n",
      "+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flights_summary_df.groupBy(\"origin_airport\",\"dest_airport\")\n",
    " .agg(sum(\"flights_count\").alias(\"sum_flights_count\"))\n",
    " .orderBy(\"sum_flights_count\", ascending=False)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fdd69a66-6240-4d09-929d-42c9864f56d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "|      origin_airport|sum_flights_count|max_flights_count|min_flights_count|count_flights_count|\n",
      "+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "|Hartsfield-Jackso...|           346836|             8234|                1|                169|\n",
      "|Chicago O'Hare In...|           285884|             9575|                2|                162|\n",
      "|Dallas/Fort Worth...|           239551|             7870|               63|                148|\n",
      "|Denver Internatio...|           196055|             7211|                2|                139|\n",
      "|Los Angeles Inter...|           194673|            13457|                1|                 80|\n",
      "|San Francisco Int...|           148008|            13744|                1|                 80|\n",
      "|Phoenix Sky Harbo...|           146815|             7380|                1|                 79|\n",
      "|George Bush Inter...|           146622|             4513|                1|                119|\n",
      "|McCarran Internat...|           133181|             9715|                9|                 78|\n",
      "|Minneapolis-Saint...|           112117|             6296|                1|                120|\n",
      "|Orlando Internati...|           110982|             8202|                7|                 74|\n",
      "|Seattle-Tacoma In...|           110899|             7765|               13|                 73|\n",
      "|Detroit Metropoli...|           108500|             4857|                1|                112|\n",
      "|Gen. Edward Lawre...|           107847|             7687|                1|                 62|\n",
      "|Newark Liberty In...|           101772|             5097|                1|                 88|\n",
      "|Charlotte Douglas...|           100324|             6307|                5|                 69|\n",
      "|LaGuardia Airport...|            99605|             9639|                1|                 69|\n",
      "|Salt Lake City In...|            97210|             6184|                1|                 89|\n",
      "|John F. Kennedy I...|            93811|            12016|                4|                 64|\n",
      "|Baltimore-Washing...|            86079|             5837|                6|                 67|\n",
      "+--------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flights_summary_df.groupBy(\"origin_airport\")\n",
    " .agg(sum(\"flights_count\").alias(\"sum_flights_count\"),\n",
    "      max(\"flights_count\").alias(\"max_flights_count\"),\n",
    "      min(\"flights_count\").alias(\"min_flights_count\"),\n",
    "      count(\"flights_count\").alias(\"count_flights_count\"))\n",
    " .orderBy(\"sum_flights_count\", ascending=False)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
